{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "690f98f7-648f-4146-8aa4-6a47fbb72883",
    "_uuid": "d6576d078c298c71f783ae570d9e1941be2924ed"
   },
   "source": [
    "# Análise de Sentimentos em língua portuguesa do Brasil\n",
    "\n",
    "Exemplo didático de análise de sentimentos a partir de uma base de dados de tweets classificados como positivo, negativo e neutro. Baseado no trabalho do Minerando Dados (https://github.com/minerandodados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "6f03ca1a-3c0e-4e33-9ba6-91a9d640185f",
    "_uuid": "2840dd041b764e287b641cc8308c68c520796d9b"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] O sistema não pode encontrar o arquivo especificado",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Codes\\IA\\LISTA 3 EXTRA\\sentiment-analysis-in-portuguese.ipynb Célula 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Codes/IA/LISTA%203%20EXTRA/sentiment-analysis-in-portuguese.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Input data files are available in the \"../input/\" directory.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Codes/IA/LISTA%203%20EXTRA/sentiment-analysis-in-portuguese.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Codes/IA/LISTA%203%20EXTRA/sentiment-analysis-in-portuguese.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msubprocess\u001b[39;00m \u001b[39mimport\u001b[39;00m check_output\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Codes/IA/LISTA%203%20EXTRA/sentiment-analysis-in-portuguese.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(check_output([\u001b[39m\"\u001b[39;49m\u001b[39mls\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m-l\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m../input\u001b[39;49m\u001b[39m\"\u001b[39;49m])\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Codes/IA/LISTA%203%20EXTRA/sentiment-analysis-in-portuguese.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Any results you write to the current directory are saved as output.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:466\u001b[0m, in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    463\u001b[0m         empty \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    464\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m empty\n\u001b[1;32m--> 466\u001b[0m \u001b[39mreturn\u001b[39;00m run(\u001b[39m*\u001b[39;49mpopenargs, stdout\u001b[39m=\u001b[39;49mPIPE, timeout\u001b[39m=\u001b[39;49mtimeout, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    467\u001b[0m            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mstdout\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    550\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m, timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] O sistema não pode encontrar o arquivo especificado"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"-l\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a9cdc1e8-0e19-4f98-a377-1a8efa50331c",
    "_uuid": "af447214f6b3b7791f19e4a17488198659a5e6ab"
   },
   "source": [
    "## 1. O Dataset de Tweets\n",
    "Vamos começar inspecionando nosso dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f1f48f72-4db1-4734-8723-9ef52aedc7b0",
    "_uuid": "7b761277e1b96610ba67f19b27b52d6658acd2bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   8199\n",
       "Created At                   8199\n",
       "Text                         8199\n",
       "Geo Coordinates.latitude      104\n",
       "Geo Coordinates.longitude     104\n",
       "User Location                5489\n",
       "Username                     8199\n",
       "User Screen Name             8199\n",
       "Retweet Count                8199\n",
       "Classificacao                8199\n",
       "Observação                      1\n",
       "Unnamed: 10                     0\n",
       "Unnamed: 11                     0\n",
       "Unnamed: 12                     0\n",
       "Unnamed: 13                     0\n",
       "Unnamed: 14                     0\n",
       "Unnamed: 15                     0\n",
       "Unnamed: 16                     0\n",
       "Unnamed: 17                     0\n",
       "Unnamed: 18                     0\n",
       "Unnamed: 19                     0\n",
       "Unnamed: 20                     0\n",
       "Unnamed: 21                     0\n",
       "Unnamed: 22                     0\n",
       "Unnamed: 23                     0\n",
       "Unnamed: 24                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primeiro, vamos contar a quantidade total de registros\n",
    "dataset = pd.read_csv('../input/Tweets_Mg.csv',encoding='utf-8')\n",
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2cfc532-207d-4d45-9110-bfefafa97b2a",
    "_uuid": "cf33f8ba0a1faf5aced6cb0769d39407ac08ee76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   2453\n",
       "Created At                   2453\n",
       "Text                         2453\n",
       "Geo Coordinates.latitude      102\n",
       "Geo Coordinates.longitude     102\n",
       "User Location                1712\n",
       "Username                     2453\n",
       "User Screen Name             2453\n",
       "Retweet Count                2453\n",
       "Classificacao                2453\n",
       "Observação                      0\n",
       "Unnamed: 10                     0\n",
       "Unnamed: 11                     0\n",
       "Unnamed: 12                     0\n",
       "Unnamed: 13                     0\n",
       "Unnamed: 14                     0\n",
       "Unnamed: 15                     0\n",
       "Unnamed: 16                     0\n",
       "Unnamed: 17                     0\n",
       "Unnamed: 18                     0\n",
       "Unnamed: 19                     0\n",
       "Unnamed: 20                     0\n",
       "Unnamed: 21                     0\n",
       "Unnamed: 22                     0\n",
       "Unnamed: 23                     0\n",
       "Unnamed: 24                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora, apenas os classificados como neutro\n",
    "dataset[dataset.Classificacao == 'Neutro'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e3d854fb-edab-4a8c-a22a-c41782f1db5a",
    "_uuid": "ab681c0af0991060c8b176adf95d0438097715f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   3300\n",
       "Created At                   3300\n",
       "Text                         3300\n",
       "Geo Coordinates.latitude        1\n",
       "Geo Coordinates.longitude       1\n",
       "User Location                2118\n",
       "Username                     3300\n",
       "User Screen Name             3300\n",
       "Retweet Count                3300\n",
       "Classificacao                3300\n",
       "Observação                      1\n",
       "Unnamed: 10                     0\n",
       "Unnamed: 11                     0\n",
       "Unnamed: 12                     0\n",
       "Unnamed: 13                     0\n",
       "Unnamed: 14                     0\n",
       "Unnamed: 15                     0\n",
       "Unnamed: 16                     0\n",
       "Unnamed: 17                     0\n",
       "Unnamed: 18                     0\n",
       "Unnamed: 19                     0\n",
       "Unnamed: 20                     0\n",
       "Unnamed: 21                     0\n",
       "Unnamed: 22                     0\n",
       "Unnamed: 23                     0\n",
       "Unnamed: 24                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Os classificados como positivo\n",
    "dataset[dataset.Classificacao == 'Positivo'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1241d7f5-12c6-4f4f-9c0f-4355f1195d8f",
    "_uuid": "d8c95fe8a2ff1114161f3af20a87dfabb80d3048"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   2446\n",
       "Created At                   2446\n",
       "Text                         2446\n",
       "Geo Coordinates.latitude        1\n",
       "Geo Coordinates.longitude       1\n",
       "User Location                1659\n",
       "Username                     2446\n",
       "User Screen Name             2446\n",
       "Retweet Count                2446\n",
       "Classificacao                2446\n",
       "Observação                      0\n",
       "Unnamed: 10                     0\n",
       "Unnamed: 11                     0\n",
       "Unnamed: 12                     0\n",
       "Unnamed: 13                     0\n",
       "Unnamed: 14                     0\n",
       "Unnamed: 15                     0\n",
       "Unnamed: 16                     0\n",
       "Unnamed: 17                     0\n",
       "Unnamed: 18                     0\n",
       "Unnamed: 19                     0\n",
       "Unnamed: 20                     0\n",
       "Unnamed: 21                     0\n",
       "Unnamed: 22                     0\n",
       "Unnamed: 23                     0\n",
       "Unnamed: 24                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E finalmente, os classificados como negativo\n",
    "dataset[dataset.Classificacao == 'Negativo'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "978a0209-71be-443d-8748-88f7c1cef6c5",
    "_uuid": "7c04a528851a3fa57b89a1ad33826456a423e7f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Created At</th>\n",
       "      <th>Text</th>\n",
       "      <th>Geo Coordinates.latitude</th>\n",
       "      <th>Geo Coordinates.longitude</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Username</th>\n",
       "      <th>User Screen Name</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Classificacao</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sun Jan 08 01:22:05 +0000 2017</td>\n",
       "      <td>���⛪ @ Catedral de Santo Antônio - Governador ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Leonardo C Schneider</td>\n",
       "      <td>LeoCSchneider</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun Jan 08 01:49:01 +0000 2017</td>\n",
       "      <td>� @ Governador Valadares, Minas Gerais https:/...</td>\n",
       "      <td>-41.9333</td>\n",
       "      <td>-18.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wândell</td>\n",
       "      <td>klefnews</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sun Jan 08 01:01:46 +0000 2017</td>\n",
       "      <td>�� @ Governador Valadares, Minas Gerais https:...</td>\n",
       "      <td>-41.9333</td>\n",
       "      <td>-18.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wândell</td>\n",
       "      <td>klefnews</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wed Jan 04 21:43:51 +0000 2017</td>\n",
       "      <td>��� https://t.co/BnDsO34qK0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ana estudando</td>\n",
       "      <td>estudandoconcur</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon Jan 09 15:08:21 +0000 2017</td>\n",
       "      <td>��� PSOL vai questionar aumento de vereadores ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Milly777</td>\n",
       "      <td>0</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      Created At  \\\n",
       "0           0  Sun Jan 08 01:22:05 +0000 2017   \n",
       "1           1  Sun Jan 08 01:49:01 +0000 2017   \n",
       "2           2  Sun Jan 08 01:01:46 +0000 2017   \n",
       "3           3  Wed Jan 04 21:43:51 +0000 2017   \n",
       "4           4  Mon Jan 09 15:08:21 +0000 2017   \n",
       "\n",
       "                                                Text  \\\n",
       "0  ���⛪ @ Catedral de Santo Antônio - Governador ...   \n",
       "1  � @ Governador Valadares, Minas Gerais https:/...   \n",
       "2  �� @ Governador Valadares, Minas Gerais https:...   \n",
       "3                        ��� https://t.co/BnDsO34qK0   \n",
       "4  ��� PSOL vai questionar aumento de vereadores ...   \n",
       "\n",
       "   Geo Coordinates.latitude  Geo Coordinates.longitude User Location  \\\n",
       "0                       NaN                        NaN        Brasil   \n",
       "1                  -41.9333                     -18.85           NaN   \n",
       "2                  -41.9333                     -18.85           NaN   \n",
       "3                       NaN                        NaN           NaN   \n",
       "4                       NaN                        NaN           NaN   \n",
       "\n",
       "               Username User Screen Name  Retweet Count Classificacao  \\\n",
       "0  Leonardo C Schneider    LeoCSchneider              0        Neutro   \n",
       "1               Wândell         klefnews              0        Neutro   \n",
       "2               Wândell         klefnews              0        Neutro   \n",
       "3         Ana estudando  estudandoconcur              0        Neutro   \n",
       "4                 Emily         Milly777              0      Negativo   \n",
       "\n",
       "      ...      Unnamed: 15  Unnamed: 16  Unnamed: 17  Unnamed: 18  \\\n",
       "0     ...              NaN          NaN          NaN          NaN   \n",
       "1     ...              NaN          NaN          NaN          NaN   \n",
       "2     ...              NaN          NaN          NaN          NaN   \n",
       "3     ...              NaN          NaN          NaN          NaN   \n",
       "4     ...              NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 19  Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 24  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OK, vamos dar uma olhada rápida no conteúdo do dataset para finalizar esse passo\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f39fe03f-981f-4629-b79a-50098dd59924",
    "_uuid": "73de912a022494b152d915d3ea31ca18c14d718b"
   },
   "source": [
    "## 2. Construindo o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eca2a77a-f355-41c5-ad4a-dfbe32af62f4",
    "_uuid": "0b90c933012a38041e975f66a60f377915b92112"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['���⛪ @ Catedral de Santo Antônio - Governador Valadares/MG https://t.co/JSbKamIqUJ',\n",
       "       '� @ Governador Valadares, Minas Gerais https://t.co/B3ThIDJCSf',\n",
       "       '�� @ Governador Valadares, Minas Gerais https://t.co/dPkgzVR2Qw',\n",
       "       ...,\n",
       "       'Trio é preso suspeito de roubo, tráfico e abuso sexual em Uberlândia https://t.co/zaQbXRRJWc',\n",
       "       'Trio é preso suspeito de roubo, tráfico e abuso sexual em Uberlândia: Um dos autores teria molestado vítima de… https://t.co/lQ8cTSNftA',\n",
       "       'Trio suspeito de roubo de cargas é preso em Santa Luzia (MG) https://t.co/0INgJcMtZb #R7MG #RecordTVMinas'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Próximo passo, vamos separar os tweets e suas classes\n",
    "tweets = dataset[\"Text\"].values\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "69e04867-3f0f-47d2-88f5-df2127042d1b",
    "_uuid": "866709548dc8dabc53c1c758f0bfdf410182a19d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutro', 'Neutro', 'Neutro', ..., 'Positivo', 'Positivo',\n",
       "       'Positivo'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = dataset[\"Classificacao\"].values\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "007fbaef-b5d0-4fd7-92cc-2583ba668179",
    "_uuid": "a376262987475125694411ecb7e129f07e84e8f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora, vamos treinar o modelo usando a abordagem Bag of Words e o algoritmo Naive Bayes Multinomial\n",
    "#    - Bag of Words, na prática, cria um vetor com cada uma das palavras do texto completo da base,\n",
    "#      depois, calcula a frequência em que essas palavras ocorrem em uma data sentença, para então\n",
    "#      classificar/treinar o modelo\n",
    "#    - Exemplo HIPOTÉTICO de três sentenças vetorizadas \"por palavra\" e classificadas baseada na\n",
    "#      frequência de suas palavras:\n",
    "#         {0,3,2,0,0,1,0,0,0,1, Positivo}\n",
    "#         {0,0,1,0,0,1,0,1,0,0, Negativo}\n",
    "#         {0,1,1,0,0,1,0,0,0,0, Neutro}\n",
    "#    - Olhando para esses vetores, meu palpite é que as palavras nas posições 2 e 3 são as com maior\n",
    "#      peso na determinação de a que classe pertence cada uma das três sentenças avaliadas\n",
    "#    - A função fit_transform faz exatamente esse processo: ajusta o modelo, aprende o vocabulário,\n",
    "#      e transforma os dados de treinamento em feature vectors, a.k.a. vetor com frequêcia das palavras\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\")\n",
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "466d7f29-032e-4dec-9602-94dd38109d3a",
    "_uuid": "f55fb6c880a34170862eaf35be8f594d9e280460"
   },
   "source": [
    "## 3. Testando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "455dcddd-6b44-4a28-97c3-fa08f0fee171",
    "_uuid": "68bc8d6fc38abf056dca0a39b687d1c381f8fd25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutro', 'Neutro', 'Negativo', 'Negativo', 'Neutro', 'Positivo'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos usar algumas frases de teste para fazer a classificação com o modelo treinado\n",
    "testes = [\"Esse governo está no início, vamos ver o que vai dar\",\n",
    "          \"Estou muito feliz com o governo de São Paulo esse ano\",\n",
    "          \"O estado de Minas Gerais decretou calamidade financeira!!!\",\n",
    "          \"A segurança desse país está deixando a desejar\",\n",
    "          \"O governador de Minas é do PT\",\n",
    "          \"O prefeito de São Paulo está fazendo um ótimo trabalho\"]\n",
    "\n",
    "freq_testes = vectorizer.transform(testes)\n",
    "modelo.predict(freq_testes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "179b67d3-0050-4188-a605-b70907e14336",
    "_uuid": "170c7c69f73a7433a0554d44a98a62308e08fc9f"
   },
   "source": [
    "## 4. Avaliando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6afb7e0c-ce1c-497b-8f2f-02b75587954e",
    "_uuid": "7cff21dfc9bb07fbce32ab78ed3073b13bdc021b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutro', 'Neutro', 'Neutro', ..., 'Positivo', 'Positivo',\n",
       "       'Positivo'], dtype='<U8')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validação cruzada do modelo. Neste caso, o modelo é dividido em 10 partes, treinado em 9 e testado em 1\n",
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv = 10)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b6b63681-0961-4da4-bd40-3c73cf0884cd",
    "_uuid": "e8eb430cb4d6449c8f173c27fbac4fc4ec711bb3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8831564824978656"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quão acurada é a média do modelo?\n",
    "metrics.accuracy_score(classes, resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a2b917b7-da10-4403-b0a7-f6f88897e29d",
    "_uuid": "1fb21da856cc6c4ee65f7daa95137dcdfbb51c0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positivo       0.95      0.88      0.91      3300\n",
      "    Negativo       0.89      0.93      0.91      2446\n",
      "      Neutro       0.80      0.84      0.82      2453\n",
      "\n",
      "    accuracy                           0.88      8199\n",
      "   macro avg       0.88      0.88      0.88      8199\n",
      "weighted avg       0.89      0.88      0.88      8199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Medidas de validação do modelo\n",
    "sentimentos = [\"Positivo\", \"Negativo\", \"Neutro\"]\n",
    "print(metrics.classification_report(classes, resultados, sentimentos))\n",
    "\n",
    "# Lembrando que:\n",
    "#    : precision = true positive / (true positive + false positive)\n",
    "#    : recall    = true positive / (true positive + false negative)\n",
    "#    : f1-score  = 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ffda64a4-e0cf-443c-bb53-a1a6f2024ae1",
    "_uuid": "aaa2cc41ea529a09c8a3c8fe504457b02769ea59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito   Negativo  Neutro  Positivo   All\n",
      "Real                                      \n",
      "Negativo      2275     162         9  2446\n",
      "Neutro         240    2067       146  2453\n",
      "Positivo        45     356      2899  3300\n",
      "All           2560    2585      3054  8199\n"
     ]
    }
   ],
   "source": [
    "# Vamos fazer uma matriz de confusão -- What?!?!\n",
    "print(pd.crosstab(classes, resultados, rownames = [\"Real\"], colnames=[\"Predito\"], margins=True))\n",
    "\n",
    "# Lembrando que:\n",
    "#    - Predito = O que o programa classificou como Negativo, Neutro, Positivo e All\n",
    "#    - Real    = O que é de fato Negativo, Neutro, Positivo e All\n",
    "#\n",
    "# Ou seja, somente 9 tweets eram de fato negativos e o programa classificou como positivos. Já os\n",
    "# positivos que o programa classificou como negativos foram 45, muito mais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0354f18c-b26d-42e9-b5b8-945b931cc2a0",
    "_uuid": "0c355e4fb76bd97a114473c71a49872dcd5b5c75"
   },
   "source": [
    "## 5. Melhorando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8dfc7e26-78fe-4233-89db-3795d4c360bd",
    "_uuid": "c4db254fe1fa38a0d05067708d37e65f007eb118"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Com o modelo de Bigrams, em lugar de vetorizar o texto \"por palavra\", vamos vetoriza-lo por cada\n",
    "# \"duas palavras\", tipo: Eu gosto de São Paulo => { eu gosto, gosto de, de são, são paulo }\n",
    "vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e918cdc1-a49c-4868-9218-047af413b4c5",
    "_uuid": "a6b6fe306e4a46b24150f858d88fa9b49bb58575"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutro', 'Neutro', 'Neutro', ..., 'Positivo', 'Positivo',\n",
       "       'Positivo'], dtype='<U8')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nova predição bigramada\n",
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv = 10)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eeac7ad5-01ee-495b-b014-a3cbeda59abc",
    "_uuid": "89647d6fedfb0d600c4d32bda31a95a4b7e6c83a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8954750579338944"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qual foi a acuracidade desse novo modelo?\n",
    "metrics.accuracy_score(classes, resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ac06ba72-6bd4-41c7-8175-e1604f179ee5",
    "_uuid": "3ae3973a12114a23096b0d35dfa298c36340a901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positivo       0.97      0.88      0.92      3300\n",
      "    Negativo       0.91      0.93      0.92      2446\n",
      "      Neutro       0.80      0.89      0.84      2453\n",
      "\n",
      "    accuracy                           0.90      8199\n",
      "   macro avg       0.89      0.90      0.89      8199\n",
      "weighted avg       0.90      0.90      0.90      8199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As novas medidas de validação do modelo, um pouquinho melhor que o anterior\n",
    "print(metrics.classification_report(classes, resultados, sentimentos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6ba7bd8e-30ea-42dc-929e-39bfc54ed323",
    "_uuid": "fcddb076247e620c096b02b7d5562a63d14c79ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito   Negativo  Neutro  Positivo   All\n",
      "Real                                      \n",
      "Negativo      2265     179         2  2446\n",
      "Neutro         181    2177        95  2453\n",
      "Positivo        43     357      2900  3300\n",
      "All           2489    2713      2997  8199\n"
     ]
    }
   ],
   "source": [
    "# E a nova matriz de confusão\n",
    "print(pd.crosstab(classes, resultados, rownames = [\"Real\"], colnames = [\"Predito\"], margins = True))\n",
    "\n",
    "# Mudanças em relação ao modelo anterior:\n",
    "#\n",
    "#    - Negativo-negativo = 2275 vs 2265 (piorou)\n",
    "#    - Negativo-neutro   = 162  vs 179  (piorou)\n",
    "#    - Negativo-positivo = 9    vs 2    (melhorou)\n",
    "#\n",
    "#    - Positivo-positivo = 2899 vs 2900 (melhorou)\n",
    "#    - Positivo-neutro   = 356  vs 357  (piorou)\n",
    "#    - Positivo-negativo = 45   vs 43   (melhorou)\n",
    "#\n",
    "#    - Neutro-neutro     = 2067 vs 2177 (melhorou)\n",
    "#    - Neutro-negativo   = 240  vs 181  (melhorou)\n",
    "#    - Neutro-positivo   = 146  vs 95   (melhorou)\n",
    "#\n",
    "# Tabela anterior para referência:\n",
    "#\n",
    "#    Predito   Negativo  Neutro  Positivo   All\n",
    "#    Real                                      \n",
    "#    Negativo      2275     162         9  2446\n",
    "#    Neutro         240    2067       146  2453\n",
    "#    Positivo        45     356      2899  3300\n",
    "#    All           2560    2585      3054  8199"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e110fa95-d680-4be2-9eda-1270ef26b46c",
    "_uuid": "23667044df7fc4bc823e300200974a489d4fe80d"
   },
   "source": [
    "# Bônus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "37a22b03-e440-4ad4-8281-de61479ab563",
    "_uuid": "8da2509f419ffdfcfc0441af686d91a6b9eb90fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8199x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 120891 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos reinicializar nosso bag of words com um parâmetro de máximo de features\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None,\n",
    "                             stop_words = None, max_features = 5000)\n",
    "\n",
    "# Treinar o modelo, aprender o vocabulário e transformar nossos dados de treinamento em feature vectors\n",
    "train_data_features = vectorizer.fit_transform(tweets)\n",
    "train_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85de9639-ac4a-4934-a572-949001f190bd",
    "_uuid": "5b5372b7009069ca8dff959ae95137033cb3b25e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hora de iniciar um classificador Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7d9c25be-4942-4bf0-8cb0-f018a38edb09",
    "_uuid": "99f6f55b07fbac58fb42206feb8ef3526a21981d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutro', 'Neutro', 'Neutro', ..., 'Positivo', 'Positivo',\n",
       "       'Positivo'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separar os sentimentos do dataset de tweets\n",
    "class_sentimentos = dataset[\"Classificacao\"].values\n",
    "class_sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ff88013f-fbd2-4ec4-8ec6-cc7e45b4957a",
    "_uuid": "e65add0e8b5bbd16f5e819f4794ff728539551a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajusta a forest ao dataset de treinamento usando a bag of words como feature e os sentimentos\n",
    "# como a resposta variável\n",
    "forest = forest.fit(train_data_features, class_sentimentos)\n",
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a05bc498-14b4-4f7f-b7a7-d308d0067ccd",
    "_uuid": "20aa2583db7ecf91e02bc945c6cdadde568abd63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 45 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar a bag of words de teste\n",
    "test_data_features = vectorizer.transform(testes)\n",
    "test_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9e4a1300-7b5a-4f3d-ab27-d3c8f5f265ab",
    "_uuid": "de46ae32c3eeb3fd1fc1388d7573146516541100"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutro', 'Neutro', 'Neutro', 'Neutro', 'Negativo', 'Neutro'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fazer um predição\n",
    "resultados = forest.predict(test_data_features)\n",
    "resultados\n",
    "\n",
    "# Resultado que tivemos com o primeiro modelo:\n",
    "# array(['Neutro', 'Neutro', 'Negativo', 'Negativo', 'Neutro', 'Positivo'], dtype='<U8')\n",
    "#\n",
    "# Meh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "05e502f3-c4ad-44e1-9480-eb7ce21202f0",
    "_uuid": "e824df8f567108ab50f2f39aba588612bfed3dd3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Esse governo está no início, vamos ver o que v...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Estou muito feliz com o governo de São Paulo e...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>O estado de Minas Gerais decretou calamidade f...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A segurança desse país está deixando a desejar</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>O governador de Minas é do PT</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>O prefeito de São Paulo está fazendo um ótimo ...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              texto sentimento\n",
       "0   1  Esse governo está no início, vamos ver o que v...     Neutro\n",
       "1   2  Estou muito feliz com o governo de São Paulo e...     Neutro\n",
       "2   3  O estado de Minas Gerais decretou calamidade f...     Neutro\n",
       "3   4     A segurança desse país está deixando a desejar     Neutro\n",
       "4   5                      O governador de Minas é do PT   Negativo\n",
       "5   6  O prefeito de São Paulo está fazendo um ótimo ...     Neutro"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Que tal gerar uma tabelinha Pandas?\n",
    "testes_id = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "data_frame = pd.DataFrame(data = { \"id\": testes_id, \"texto\": testes, \"sentimento\": resultados })\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b2f278ac-2ff5-49dc-9461-b4b62d45c30a",
    "_uuid": "507f81f018ac63e1c7f46ac5140d178b0f3d8297"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\n",
      "-rw-r--r-- 1 root root 15336 Aug 19 12:58 __notebook__.ipynb\n",
      "-rw-r--r-- 1 root root   270 Aug 19 12:58 __output__.json\n",
      "-rw-r--r-- 1 root root   385 Aug 19 12:59 tweets_classificados_por_forest.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# E finalmente, vamos salvar nossa predição em um .csv\n",
    "data_frame.to_csv(\"tweets_classificados_por_forest.csv\", index = False, quoting = 3, escapechar = \"\\\\\")\n",
    "print(check_output([\"ls\", \"-l\", \".\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5d1e2db8-a0b7-49de-ba13-f501cfc9d86d",
    "_uuid": "c4675aedf2a2e46b5642fbe8fd9f78c74a26cc74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,texto,sentimento\n",
      "1,Esse governo está no início\\, vamos ver o que vai dar,Neutro\n",
      "2,Estou muito feliz com o governo de São Paulo esse ano,Neutro\n",
      "3,O estado de Minas Gerais decretou calamidade financeira!!!,Neutro\n",
      "4,A segurança desse país está deixando a desejar,Neutro\n",
      "5,O governador de Minas é do PT,Negativo\n",
      "6,O prefeito de São Paulo está fazendo um ótimo trabalho,Neutro\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OK, ok, vamos dar só mais uma espiada para ver se deu tudo certo\n",
    "print(check_output([\"cat\", \"tweets_classificados_por_forest.csv\"]).decode(\"utf8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
